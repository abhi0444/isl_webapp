# India Sign Language Recognition

## 1 . Project Overview

Many people in India are speech and/or hearing impaired, and they thus use hand gestures to communicate with other people. However, apart from a handful of people, not everyone is aware of this sign language and they may require an interpreter which can be inconvenient and expensive. This project aims to narrow this communication gap by developing software which can predict the ISL alphanumeric hand gestures.

## 2 . Novely of Work

1 . This work proposes a supervised framework with deep convolutional neural networks (CNNs) for vision-based sign language recognition for static gestures. 

2 . Our approach addresses the acquisition and segmentation of correct inputs for the CNN based classifier. 

3 . Cropped images of hands in different poses used to depict different Indian Sign language gestures are used as an input for our classifier.

4 . The system was trained and tested on static ISL (Indian Sign Language) gestures of alphabets, letters, and some words. 

5 . The system is developed as a proof of concept model for static gesture based sign language recognition.

## 4 . Flowchart

![alt text](https://github.com/abhi0444/isl_webapp/blob/main/static/images/1st.jpeg)

## 5 . Output Screeshorts

![alt text](https://github.com/abhi0444/isl_webapp/blob/main/static/images/3rd.jpeg)

## 6 . Dataset Example Images

![alt text](https://github.com/abhi0444/isl_webapp/blob/main/static/images/4th.JPG)


